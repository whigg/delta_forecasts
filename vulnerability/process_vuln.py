import csv
import json
import pandas

def import_idi_vuln(env, target, source):
    colname = env['colname']

    def clean_name(s):
        return s.replace(' ','_').replace('-','_')

    with open(str(source[0]), 'r') as fd:
        fd.readline()
        fd.readline()
        csvfile = csv.DictReader(fd)

        deltas = pandas.read_pickle(str(source[1]))

        vuln = pandas.Series(index=deltas.index)
        for rec in csvfile:
            vuln[clean_name(rec['Delta'])] = float(rec[colname])

    vuln.to_pickle(str(target[0]))
    return 0


def import_wgi(env, target, source):
    def rename_country(c):
        if c == 'Egypt':
            return 'Egypt, Arab Rep.'
        elif c == 'Iran':
            return 'Iran, Islamic Rep.'
        elif c == 'South Korea':
            return 'Korea, Rep.'
        elif c == 'North Korea':
            return 'Korea, Dem. Rep.'
        elif c == 'Russia':
            return 'Russian Federation'
        elif c == 'Burma':
            return 'Myanmar'
        elif c == 'Macau (China)':
            return 'Macao SAR, China'
        elif c == 'Venezuela':
            return 'Venezuela, RB'
        elif c == 'Congo (Kinshasa)':
            return 'Congo, Rep.'
        else:
            return c

    xls = pandas.read_excel(str(source[0]), sheetname='GovernmentEffectiveness', skiprows=13, header=[0,1], index_col=0)
    with open(str(source[1]), 'r') as fin:
        allcountries = json.load(fin)
    deltas = pandas.read_pickle(str(source[2]))
    for delta, dcountries in allcountries.iteritems():
        wgi_sum = 0
        for country, areainfo in dcountries.iteritems():
            wgi_sum += areainfo['area_frac'] * xls.loc[rename_country(country), (2016, 'Estimate')]
        deltas[delta] = wgi_sum
    deltas.to_pickle(str(target[0]))
    return 0


def unity_norm_gov(env, source, target):
    gov = pandas.read_pickle(str(source[0]))
    gov_norm = (gov - gov.min()) / (gov.max() - gov.min())
    gov_norm.to_pickle(str(target[0]))
    return 0


def compute_unity_norm_econ_vuln(env, source, target):
    '''
    Normalize to 0-1 range relative to reference value
    '''
    gdp = pandas.read_pickle(str(source[0]))
    percap = pandas.read_pickle(str(source[1]))

    gdp_ref = pandas.read_pickle(str(source[2]))
    percap_ref = pandas.read_pickle(str(source[3]))
    ref_year = env['ref_year']

    # normalize to min/max across all deltas, all SSPs, all years
    # maintain reference scale from un-adjusted capacity sources (ie, before adjusting for energy cost, ...)
    # adjusted values may be outside of 0-1 range
    def ref_min(x):
        '''
        Take values from specific year, min across SSPs, min across deltas
        '''
        return x.loc[:, (slice(None), ref_year)].min().min()
    def ref_max(x):
        '''
        Take values from specific year, max across SSPs, max across deltas
        '''
        return x.loc[:, (slice(None), ref_year)].max().max()

    gdp_normed = (gdp - ref_min(gdp_ref)) / (ref_max(gdp_ref) - ref_min(gdp_ref))
    gdp_ref_normed = (gdp_ref - ref_min(gdp_ref)) / (ref_max(gdp_ref) - ref_min(gdp_ref))

    percap_normed = (percap - ref_min(percap_ref)) / (ref_max(percap_ref) - ref_min(percap_ref))
    percap_ref_normed = (percap_ref - ref_min(percap_ref)) / (ref_max(percap_ref) - ref_min(percap_ref))

    econ_capacity = gdp_normed + percap_normed
    econ_capacity_ref = gdp_ref_normed + percap_ref_normed
    econ_capacity_normed = (econ_capacity - ref_min(econ_capacity_ref)) / (ref_max(econ_capacity_ref) - ref_min(econ_capacity_ref))

    econ_vuln_normed = 1 - econ_capacity_normed

    econ_capacity_normed.to_pickle(str(target[0]))
    econ_vuln_normed.to_pickle(str(target[1]))
    return 0


def extract_energy_cost_index_from_eia_outlook(env, source, target):
    data = pandas.read_csv(str(source[0]), header=4) # some manual edits made to csv to fix string quoting
    key = env['key']
    to_year = 2100

    data = data.set_index('api key')
    data = data.drop(['Unnamed: 0', 'full name', 'units'], axis=1)
    energy_index = data.loc[key]

    # growth rate is computed by EIA, but starting at 2016 rather than 2015. do manually
    # growth_rate = float(energy_index.iloc[-1].replace('%',''))/100.
    energy_index = energy_index.iloc[:-1]
    energy_index.index = [int(i) for i in energy_index.index]
    y1, y2 = energy_index.index[[0, -1]]
    growth_rate = (energy_index[y2]/energy_index[y1]) ** (1./(y2-y1)) - 1

    # extrapolate out based on 2015-2050 growth rate
    for year in range(energy_index.index[-1]+1, to_year+1):
        energy_index[year] = energy_index[year-1] * (1 + growth_rate)

    energy_index.to_pickle(str(target[0]))
    return 0


def adj_gdp_for_energy_prices(env, source, target):
    '''
    Discount GDP based on energy cost index growth from baseline (2016)
    '''
    gdp = pandas.read_pickle(str(source[0]))
    percap = pandas.read_pickle(str(source[1]))
    energy_index = pandas.read_pickle(str(source[2]))

    gdp_adj = pandas.DataFrame(index=gdp.index, columns=gdp.columns)
    percap_adj = pandas.DataFrame(index=percap.index, columns=percap.columns)
    for (ssp, year), gdps in gdp.iteritems():
        gdp_adj.loc[:, (ssp, year)] = gdps / (energy_index.get(year, energy_index.iloc[0]) / energy_index.iloc[0])
    for (ssp, year), percaps in percap.iteritems():
        percap_adj.loc[:, (ssp, year)] = percaps / (energy_index.get(year, energy_index.iloc[0]) / energy_index.iloc[0])

    gdp_adj.to_pickle(str(target[0]))
    percap_adj.to_pickle(str(target[1]))
    return 0


def stack_capacity_indicators(env, source, target):
    econ = pandas.read_pickle(str(source[0]))
    gov = pandas.read_pickle(str(source[1]))

    stack = econ.add(gov, axis=0)
    stack.to_pickle(str(target[0]))
    return 0


def vuln_from_capacity(env, source, target):
    cap = pandas.read_pickle(str(source[0]))
    vuln = cap.max().max() - cap
    vuln.to_pickle(str(target[0]))
    return 0
